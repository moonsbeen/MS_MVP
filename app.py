import streamlit as st
import pandas as pd
import json
import os
import sqlite3
import chardet  
from io import StringIO  
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI  
from langchain.schema import SystemMessage, HumanMessage
from langchain_community.chat_models import AzureChatOpenAI
from azure.storage.blob import BlobServiceClient

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env ì½ì–´ì„œ ë©”ëª¨ë¦¬ì— load)
load_dotenv() 
api_key = os.getenv("OPENAI_API_KEY")  
api_azure_endpoint = os.getenv("OPENAI_ENDPOINT")  
api_type = os.getenv("OPENAI_API_TYPE")  
api_version = os.getenv("OPENAI_API_VERSION")  
chat_deployment_name = os.getenv("CHAT_DEPLOYMENT_NAME") 
azure_blob = os.getenv("AZURE_STOREGE_CONNECTION_STRING") 
azure_container = os.getenv("AZURE_STORAGE_CONTAINER") 

# ì´ˆê¸° ì„¸ì…˜ ì •ì˜
if "query" not in st.session_state:
  st.session_state.query = ""
if "converted_sql" not in st.session_state:
  st.session_state.converted_sql = None
if "csv_uploaded" not in st.session_state:
  st.session_state.csv_uploaded = False
if "upload_file" not in st.session_state:
  st.session_state.upload_file = None 

# SQL ë³€í™˜ í•¨ìˆ˜ (Langchain, Azure OpenAI)
def convert_sql(query: str, source : str, target: str):
  llm = AzureChatOpenAI (
      openai_api_key=api_key,
      azure_endpoint=api_azure_endpoint,
      deployment_name=chat_deployment_name,
      openai_api_version=api_version,
      openai_api_type=api_type,
      temperature=0
  ) 
  
  prompt = f"""
    ë‹¹ì‹ ì€ SQL ë³€í™˜ ì „ë¬¸ê°€ ì…ë‹ˆë‹¤.
    ì•„ë˜ SQL ì¿¼ë¦¬ëŠ” {source} DBMS ìš©ì…ë‹ˆë‹¤.
    ì´ë¥¼ {target} DBMS ë¬¸ë²•ì— ë§ê²Œ ì •í™•íˆ ë³€í™˜í•´ ì£¼ì„¸ìš”.

    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ **ì•„ë˜ JSON í˜•ì‹**ì„ ë”°ë¥´ì„¸ìš”.
    ë‹¤ë¥¸ ë§ì´ë‚˜ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    ì˜ˆì‹œ í˜•ì‹:
    {{
      "source_dbms": "{source}",
      "target_dbms": "{target}",
      "conversion_notes": "<í•œêµ­ì–´ë¡œ ì–´ë–¤ ë¬¸ë²•ì„ ì™œ ë°”ê¿¨ëŠ”ì§€ ê°„ë‹¨íˆ ìš”ì•½, SQLë¬¸ì—ëŒ€í•œ ê°„ë‹¨í•œ í•´ì„ ë“±>",
      "converted_sql": "<ë³€í™˜ëœ SQL ì¿¼ë¦¬ ë‚´ìš©>"
    }}

    ì›ë³¸ sql ì¿¼ë¦¬: {query}
  """

  messages = [
    SystemMessage(content="ë‹¹ì‹ ì€ ì „ë¬¸ sql ë³€í™˜ê¸°ì…ë‹ˆë‹¤."),
    HumanMessage(content=prompt)
  ]

  return llm(messages).content.strip()

def detect_source_db(query: str) -> str:
  llm = AzureChatOpenAI(   
    openai_api_key=api_key,
    azure_endpoint=api_azure_endpoint,
    deployment_name=chat_deployment_name,
    openai_api_version=api_version,
    openai_api_type=api_type,
    temperature=0
  )

  messages = [
    SystemMessage(content="ë‹¹ì‹ ì€ SQL ë¶„ì„ ì „ë¬¸ê°€ ì…ë‹ˆë‹¤."),
    HumanMessage(content=f"""
      ë‹¤ìŒ SQLì€ ì–´ë–¤ DBMSì˜ ë¬¸ë²•ì…ë‹ˆê¹Œ?
      sql
      {query}
      )
      ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•œ ë‹¨ì–´ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”: Oracle, Mysql, Mssql, Postgersql, Teradata, Nosql
      """)
  ] 

  result = llm(messages).content.strip().split()[0].capitalize()
  if result not in ["Oracle", "Mysql", "Mssql", "Postgersql"]:
    return "Unknown"
  return result

def upload_to_blob(file, filename):    
  try:   
    # BlobServiceClient ìƒì„±  
    blob_service_client = BlobServiceClient.from_connection_string(azure_blob)           
    # BlobClient ìƒì„±  
    blob_client = blob_service_client.get_blob_client(container=azure_container, blob=filename)     
    # íŒŒì¼ ì—…ë¡œë“œ  
    blob_client.upload_blob(file.getvalue(), overwrite=True)  # overwrite=Trueë¡œ ë®ì–´ì“°ê¸° ê°€ëŠ¥            
    #st.success(f"File {file.name} uploaded to Blob Storage successfully!")  

    # ì‹¤ì œ URL ìƒì„±  
    blob_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{azure_container}/{filename}"  
    return blob_url  # ì‹¤ì œ URL ë°˜í™˜  
  except Exception as e:  
    st.error(f"Error uploading file: {e}")  
    return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜  

def load_and_join_csv_from_blob(connection_string, container_name, join_query):  
  # 1. BlobServiceClient ìƒì„±  
  blob_service_client = BlobServiceClient.from_connection_string(connection_string)  

  # 2. ì»¨í…Œì´ë„ˆ í´ë¼ì´ì–¸íŠ¸ ìƒì„±  
  container_client = blob_service_client.get_container_client(container_name)  
  
  # 3. Blob ëª©ë¡ ê°€ì ¸ì˜¤ê¸°  
  blobs = container_client.list_blobs()  
  
  dataframes = {}  
  for blob in blobs:  
    if blob.name.endswith('.csv'):  # CSV íŒŒì¼ í•„í„°ë§  
      # Blob ë‹¤ìš´ë¡œë“œ  
      blob_client = container_client.get_blob_client(blob)  
      stream = blob_client.download_blob()  
      csv_data = stream.content_as_bytes()  # ë°”ì´íŠ¸ í˜•íƒœë¡œ ë‹¤ìš´ë¡œë“œ  
  
      # ì¸ì½”ë”© ê°ì§€  
      result = chardet.detect(csv_data)  
      encoding = result['encoding']  
  
      # CSV ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜  
      df = pd.read_csv(StringIO(csv_data.decode(encoding)), encoding=encoding)  
  
      # íŒŒì¼ ì´ë¦„ì„ í…Œì´ë¸” ì´ë¦„ìœ¼ë¡œ ì‚¬ìš© (í™•ì¥ì ì œê±°)  
      table_name = blob.name.split('.')[0]  
      dataframes[table_name] = df  
  
  # 5. SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ë©”ëª¨ë¦¬ ë‚´ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)  
  conn = sqlite3.connect(':memory:')  
  
  # 6. DataFrameì„ SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥  
  for table_name, df in dataframes.items():  
    df.to_sql(table_name, conn, index=False, if_exists='replace')  
  
  # 7. SQL ì¡°ì¸ ì¿¼ë¦¬ ì‹¤í–‰  
  result = pd.read_sql_query(join_query, conn)  
   
  conn.close()  
  return result  
  

# í˜ì´ì§€ ì„¤ì •  
st.set_page_config(page_title="SQL ë³€í™˜ê¸°", layout="wide")  
st.title("ğŸ§¸ AI ê¸°ë°˜ SQL ë³€í™˜ ë° ì‹¤í–‰ê¸°")  
  
# ì´ˆê¸°í™” ë²„íŠ¼  
if st.button("ğŸ” ì´ˆê¸°í™”"):  
  st.session_state.query = ""  
  st.session_state.converted_sql = None
  st.session_state.csv_uploaded = False  
  st.session_state.upload_file = None 
  
dbms_options = ["Oracle", "Mysql", "Postgresql", "Mssql", "Teradata", "Nosql"]    
target_db = st.selectbox("âœ ë³€í™˜í•  DBMS ì„ íƒ", dbms_options, index=dbms_options.index(st.session_state.get("target_db", dbms_options[0])))  
  
# SQL ì¿¼ë¦¬ ì…ë ¥ 
st.session_state.query = st.text_area("ë³€í™˜í•  SQL ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", st.session_state.get("query", ""), height=200)  
  
if st.button("SQL ë³€í™˜í•˜ê¸°"):  
  if not st.session_state.query.strip():  
      st.warning("SQL ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")  
  else:  
    with st.spinner("ì›ë³¸ DBMS ê°ì§€ ì¤‘..."):  
      detected_source_db = detect_source_db(st.session_state.query)  # DBMS ê°ì§€ í•¨ìˆ˜ í˜¸ì¶œ  
  
    if detected_source_db == "Unknown":  
      st.error("ì›ë³¸ DBMSë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")  
    else:  
      #st.success(f"ê°ì§€ëœ DBMS: `{detected_source_db}`   ë³€í™˜í•  DBMS: `{target_db}`")  
      # DBMSê°€ ë™ì¼í•œì§€ í™•ì¸  
      if detected_source_db == target_db:  
        st.warning("ğŸš«ì›ë³¸ê³¼ ëŒ€ìƒ DBMSê°€ ë™ì¼í•©ë‹ˆë‹¤.ğŸš«")  
      else:  
        with st.spinner(f"GPTë¥¼ í†µí•´ ë³€í™˜ì¤‘..."):  
          json_output = convert_sql(st.session_state.query, detected_source_db, target_db)
          parsed = json.loads(json_output)
          st.session_state.converted_sql = parsed["converted_sql"]
          #st.session_state.converted_sql = convert_sql(st.session_state.query, st.session_state.source_db, target_db)  # SQL ë³€í™˜ í•¨ìˆ˜ í˜¸ì¶œ  
          st.success("ë³€í™˜ ì™„ë£Œ!")  

    # ë³€í™˜ëœ SQL í‘œì‹œ  
    if st.session_state.converted_sql:  
      st.markdown("---")
      st.markdown("### ğŸ“ƒ ë³€í™˜ ì •ë³´")
      st.markdown(f"- **ì›ë³¸ DBMS**: `{parsed['source_dbms']}`")
      st.markdown(f"- **ëŒ€ìƒ DBMS**: `{parsed['target_dbms']}`")
      st.markdown(f"- **ë³€í™˜ ìš”ì•½**: `{parsed['conversion_notes']}`")

      st.markdown("---") 
      st.markdown("### ğŸ“ƒ ë³€í™˜ëœ SQL")
      st.code(parsed["converted_sql"], language="sql") 

st.markdown("---") 
st.header("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ")
st.session_state.upload_file = st.file_uploader("CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["csv"])
if st.session_state.upload_file is not None:
  st.write(f"ì„ íƒëœ íŒŒì¼: `{st.session_state.upload_file.name}`")
  if st.button("csvíŒŒì¼ ì—…ë¡œë“œ"):
    blob_url = upload_to_blob(st.session_state.upload_file, st.session_state.upload_file.name)
    if blob_url is not None:
      st.success(f"blobì— ì—…ë¡œë“œ ì™„ë£Œ")
      st.session_state.csv_uploaded = True
    else: 
      st.write(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨")
else:
  if st.session_state.csv_uploaded:  
    st.write(f"ì´ë¯¸ ì—…ë¡œë“œëœ íŒŒì¼: `{st.session_state.upload_file}`")  
  else:  
    st.info("ë¨¼ì € CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")

if st.session_state.converted_sql:
  st.markdown("---")
  st.header("ğŸ“Š SQL í…ŒìŠ¤íŠ¸ í•˜ê¸°")
  if st.button("SQL í…ŒìŠ¤íŠ¸"):
    with st.spinner("SQL ìˆ˜í–‰ ì¤‘..."):
      try:  
        # ì¿¼ë¦¬ ì‹¤í–‰  
        result_df = load_and_join_csv_from_blob(azure_blob, azure_container, st.session_state.converted_sql)  
        # ê²°ê³¼ ì¶œë ¥  
        st.dataframe(result_df)  # Streamlitì˜ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ  
      except sqlite3.Error as e:  
        st.error(f"SQL Error: {e}")  # SQL ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥  
      except Exception as e:  
        st.error(f"Error: {e}")  # ì¼ë°˜ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
  
